---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am Xunjian Yin, a second-year Master's student in the [Wangxuan Institute of Computer Technology](https://www.icst.pku.edu.cn/english/home/index.htm) at [Peking University](https://english.pku.edu.cn/). My advisor is Prof. [Xiaojun Wan](https://wanxiaojun.github.io/). Previously, I obtained my B.S. degree in [Computer Science](https://eecs.pku.edu.cn/en/) from [Peking University](https://english.pku.edu.cn/).

My research interest lies in large language models (LLMs). Specifically, I aim to design methods that allow for a better understanding of the knowledge inside LLMs, and to go further in acquiring and editing knowledge. I also aim to devise ways to make models better at learning knowledge, and applying that knowledge to reasoning.

Recent News
======

- 2023-10: Two papers are accepted to EMNLP 2023 (one at main conference, one at findings). 


Preprints
======

- Human-like Summarization Evaluation with ChatGPT  
Mingqi Gao, Jie Ruan, Renliang Sun, **Xunjian Yin**, Shiping Yang, Xiaojun Wan  
*arXiv*:2304.02554  [[paper](https://arxiv.org/abs/2304.02554)]  

- Chinese Spelling Check with Nearest Neighbors  
**Xunjian Yin**, Xinyu Hu, Xiaojun Wan  
*arXiv*:2211.07843  [[paper](https://arxiv.org/abs/2211.07843)]

- A Comprehensive Evaluation and Analysis Study for Chinese Spelling Check     
**Xunjian Yin**, Xiaojun Wan      
 *arXiv*:2307.13655  [[paper](https://arxiv.org/abs/2307.13655)]

Publications
======

- ALCUNA: Large Language Models Meet New Knowledge  
**Xunjian Yin**\*, Baizhou Huang\*, Xiaojun Wan  
*EMNLP 2023*  [[pdf](https://arxiv.org/pdf/2310.14820v1.pdf)] [[code](https://github.com/arvid-pku/alcuna)]

- Exploring Context-Aware Evaluation Metrics for Machine Translation   
Xinyu Hu, **Xunjian Yin**, Xiaojun Wan  
*EMNLP 2023 findings*  [[pdf](TODO)] [[code](TODO)]  

- Overview of the NLPCC 2023 Shared Task: Chinese Spelling Check
**Xunjian Yin**, Xiaojun Wan, Dan Zhang, Linlin Yu, Long Yu
*NLPCC 2023* [[pdf](https://link.springer.com/chapter/10.1007/978-3-031-44699-3_30)] [[code](https://github.com/Arvid-pku/NLPCC2023_Shared_Task8)]

- How Do Seq2Seq Models Perform on End-to-End Data-to-Text Generation?    
**Xunjian Yin**, Xiaojun Wan    
*ACL 2022*  [[pdf](https://aclanthology.org/2022.acl-long.531.pdf)] [[code](https://github.com/xunjianyin/Seq2SeqOnData2Text)]  



Academic Services
======

- Reviewer: ACL 2023, ACL ARR 2023
- NLPCC Shared Task 8 track chair 

